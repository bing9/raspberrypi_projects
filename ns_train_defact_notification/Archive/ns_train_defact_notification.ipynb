{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NS delayes notification\n",
    "\n",
    "NS API address: https://www.ns.nl/en/travel-information/ns-api\n",
    "\n",
    "credentials management: https://dev.to/jamestimmins/django-cheat-sheet-keep-credentials-secure-with-environment-variables-2ah5\n",
    "https://pypi.org/project/python-dotenv/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenvb\n",
    "#!pip install osa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install jupyter_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client, urllib.request, urllib.parse, urllib.error, base64, pandas as pd\n",
    "import json\n",
    "import os\n",
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "from jupyter_helpers.namespace import NeatNamespace\n",
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "import smtplib, ssl\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from collections import defaultdict\n",
    "\n",
    "pd.set_option('display.max_columns', 300) # display 300 columns without shrinking\n",
    "pd.set_option('display.max_rows', 100) # Show more rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "# from pathlib import Path  # python3 only using specific path\n",
    "# env_path = Path('.') / '.env'\n",
    "# load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual data insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data=defaultdict()\n",
    "user_data['daily_work_leave'] = {'from_uic': 8400061, 'to_uic': 8400319, 'h':6, 'm':26, 'enabled':True}\n",
    "user_data['daily_work_return'] = {'from_uic': 8400319, 'to_uic': 8400061, 'h':16, 'm':8, 'enabled':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_data = pd.DataFrame(user_data).T\n",
    "df_user_data[df_user_data['enabled']==True]\n",
    "df_user_data['search_date_time'] = df_user_data.apply(lambda row: datetime.datetime.today().replace(hour=row.h, minute=row.m, second =0).strftime('%Y-%m-%dT%T%z') ,axis=1)\n",
    "df_user_data['current_date_time'] = datetime.datetime.today()\n",
    "df_user_data['diff'] = pd.to_datetime(df_user_data['search_date_time']) - pd.to_datetime(df_user_data['current_date_time'])\n",
    "df_user_data_input = df_user_data[df_user_data['diff']>pd.Timedelta(0, unit='s')].sort_values(by='diff').head(1).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_user_data_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation\n",
    "1. check if train is canceled\n",
    "    * Canceled train return next earliest available one\n",
    "    * And calculate waiting time\n",
    "2. check if train is delayed\n",
    "    * Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Set UIC code, stations code can be googled with universal destinations.\n",
    "# denbosch = 8400319\n",
    "# amszuid = 8400061 \n",
    "# search_date_time_leave = datetime.datetime.today().replace(hour=6, minute=26, second =0).strftime('%Y-%m-%dT%T%z')\n",
    "# search_date_time_return = datetime.datetime.today().replace(hour=16, minute=8, second =0).strftime('%Y-%m-%dT%T%z')\n",
    "# from_uic = amszuid\n",
    "# to_uic = denbosch\n",
    "# email_sent = False\n",
    "#train_id = 'IC 3519 ' # Return 3556\n",
    "#ctx_Reconn_amsz_to_denbosch = 'arnu|fromStation=8400061|toStation=8400319|plannedFromTime=2019-12-23T06:26:00+01:00|plannedArrivalTime=2019-12-23T07:21:00+01:00|yearCard=false|excludeHighSpeedTrains=false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_ns(from_uic, to_uic, search_date_time, email_sent, **kwargs):\n",
    "    # all ride information\n",
    "    # https://apiportal.ns.nl/docs/services/public-reisinformatie-api/operations/ApiV3TripsGet?\n",
    "\n",
    "    key = os.getenv(\"NS_KEY\")\n",
    "\n",
    "    headers = {\n",
    "        # Request headers\n",
    "        'Accept': '',\n",
    "        'X-Request-ID': '',\n",
    "        'X-Caller-ID': '',\n",
    "        'x-api-key': '',\n",
    "        'Authorization': '',\n",
    "        'Ocp-Apim-Subscription-Key': '%s' % key,\n",
    "    } \n",
    "\n",
    "    params = urllib.parse.urlencode({\n",
    "        # Request parameters\n",
    "        'originUicCode': '%s' % from_uic,\n",
    "        'destinationUicCode': '%s' % to_uic,\n",
    "        'dateTime': '%s' % search_date_time,\n",
    "        'previousAdvices': 2,\n",
    "        'nextAdvices': 8 ,\n",
    "    })\n",
    "\n",
    "    try:\n",
    "        conn = http.client.HTTPSConnection('gateway.apiportal.ns.nl')\n",
    "        conn.request(\"GET\", \"/public-reisinformatie/api/v3/trips?%s\" % params, \"{body}\", headers)\n",
    "        response = conn.getresponse()\n",
    "        data = response.read()\n",
    "        #print(data)\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n",
    "    \n",
    "    def date_time_column(x):\n",
    "        date_time_col=[]\n",
    "        l = list(x.columns)\n",
    "        for i in l:\n",
    "            if i.find('DateTime')==-1:\n",
    "                continue\n",
    "            else: \n",
    "                date_time_col.append(i)\n",
    "                x[i] = pd.to_datetime(x[i])\n",
    "        return x    \n",
    "    \n",
    "    \n",
    "    d = json.loads(data)\n",
    "    lenghth = len(d)\n",
    "    if lenghth >0:\n",
    "        print(f'Data successfully got from NS. len={lenghth}')\n",
    "    \n",
    "    df_unpack = json_normalize(data=d['trips'], record_path=['legs'], meta=['ctxRecon','status','transfers','plannedDurationInMinutes','actualDurationInMinutes','punctuality'\n",
    "                                                                       , 'realtime','optimal','shareUrl'], errors='ignore',meta_prefix='meta_' , sep='_')\n",
    "    #print(type(df_unpack['origin_plannedDateTime']))\n",
    "    \n",
    "    date_time_column(df_unpack)\n",
    "    \n",
    "    df_unpack['time_to_target'] = df_unpack['origin_plannedDateTime'].apply(lambda x: abs(x - pd.Timestamp(search_date_time+'+0100') ) )\n",
    "    #print(df_unpack['time_to_target'])\n",
    "    \n",
    "    #target_train = df_unpack.copy()[df_unpack['origin_plannedDateTime']==search_date_time+'+0100'].head(1)\n",
    "    target_train = df_unpack.copy().sort_values(by='time_to_target', ascending =True).head(1)\n",
    "    selected_len = len(target_train)\n",
    "\n",
    "    \n",
    "    #date_time_column(target_train)\n",
    "    \n",
    "    def status(target_train):\n",
    "        status='normal'\n",
    "        delayed_min = 0 \n",
    "        url_to_html = target_train['meta_shareUrl'].values.item()['uri']\n",
    "        if target_train['cancelled'].bool() == True:\n",
    "            status = 'cancelled'\n",
    "        else:\n",
    "            try:\n",
    "                diff = target_train['origin_actualDateTime'] - target_train['origin_plannedDateTime']\n",
    "                delayed_min = diff.values.item()/60000000000\n",
    "                if delayed_min > 5 :\n",
    "                    status = 'delayed > 5 mins'\n",
    "                else:\n",
    "                    status = 'delayed <= 5 mins'\n",
    "            except:\n",
    "                if target_train['meta_status'].values.item() != 'NORMAL':\n",
    "                    status = target_train['meta_status'].values.item()\n",
    "                else: \n",
    "                    status = 'normal'\n",
    "            pass\n",
    "\n",
    "        return status, int(delayed_min), url_to_html\n",
    "    \n",
    "    if selected_len>0:\n",
    "        print(f'Target time selected. Time={search_date_time}')\n",
    "        status, delayed_min, url_to_html = status(target_train)\n",
    "        print(f'Status {status}; Delayed {delayed_min} mins.')\n",
    "    else:\n",
    "        print(f'No train selected for time {search_date_time}')\n",
    "        \n",
    "    def send_email(status, delayed_min, url_to_html ):\n",
    "\n",
    "        sender_email = os.getenv('GMAIL_USER')\n",
    "        receiver_email = [i.strip() for i in list(os.getenv(\"SEND_TO\").split(\";\"))][1]\n",
    "        password = os.getenv('GMAIL_PWD')\n",
    "\n",
    "        message = MIMEMultipart(\"alternative\")\n",
    "        message[\"Subject\"] = 'Train '+status+'!'\n",
    "        message[\"From\"] = sender_email\n",
    "        message[\"To\"] = receiver_email\n",
    "\n",
    "        # Create the plain-text and HTML version of your message\n",
    "        text = \"\"\"\\\n",
    "        Hi,\n",
    "        \"\"\" + url_to_html\n",
    "        html = '' #requests.get(url_to_html).text \n",
    "\n",
    "        # Turn these into plain/html MIMEText objects\n",
    "        part1 = MIMEText(text, \"plain\")\n",
    "        part2 = MIMEText(html, \"html\")\n",
    "\n",
    "        # Add HTML/plain-text parts to MIMEMultipart message\n",
    "        # The email client will try to render the last part first\n",
    "        message.attach(part1)\n",
    "        message.attach(part2)\n",
    "\n",
    "        # Create secure connection with server and send email\n",
    "        context = ssl.create_default_context()\n",
    "        \n",
    "        with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465, context=context) as server:\n",
    "            server.login(sender_email, password)\n",
    "            server.sendmail(\n",
    "                sender_email, receiver_email, message.as_string()\n",
    "            )   \n",
    "    \n",
    "    if status == 'normal':\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            send_email(status, delayed_min, url_to_html)\n",
    "            email_sent = True\n",
    "        except:\n",
    "            email_sent = False\n",
    "    \n",
    "    return email_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_which_job_to_run(df_user_data_input):\n",
    "    if len(df_user_data_input)>0:\n",
    "        try:\n",
    "            email_sent = get_data_from_ns( email_sent=email_sent, **df_user_data_input[0])\n",
    "        except:\n",
    "            print('error: email not sent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# email_sent = get_data_from_ns( to_uic, from_uic, search_date_time_return, email_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_date_time_return\n",
    "# time.strptime(search_date_time_return, '%Y-%m-%dT%H:%M:%S')\n",
    "#pd.Timestamp(search_date_time_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NeatNamespace(d['trips'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_trips.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_trips.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_unpack = json_normalize(data=d['trips'], record_path=['legs'], meta=['ctxRecon','status','transfers','plannedDurationInMinutes','actualDurationInMinutes','punctuality'\n",
    "#                                                                        , 'realtime','optimal','shareUrl'], errors='ignore',meta_prefix='meta_' , sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_unpack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_unpack['meta_shareUrl'][0]['uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_unpack[df_unpack['cancelled']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_train = df_unpack.copy()[df_unpack['origin_plannedDateTime']==search_date_time+'+0100'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_train = df_unpack.copy().head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def date_time_column(x):\n",
    "#     date_time_col=[]\n",
    "#     l = list(x.columns)\n",
    "#     for i in l:\n",
    "#         if i.find('DateTime')==-1:\n",
    "#             continue\n",
    "#         else: \n",
    "#             date_time_col.append(i)\n",
    "#             x[i] = pd.to_datetime(x[i])\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>name</th>\n",
       "      <th>travelType</th>\n",
       "      <th>direction</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>changePossible</th>\n",
       "      <th>alternativeTransport</th>\n",
       "      <th>journeyDetailRef</th>\n",
       "      <th>notes</th>\n",
       "      <th>messages</th>\n",
       "      <th>stops</th>\n",
       "      <th>steps</th>\n",
       "      <th>crowdForecast</th>\n",
       "      <th>punctuality</th>\n",
       "      <th>crossPlatformTransfer</th>\n",
       "      <th>shorterStock</th>\n",
       "      <th>journeyDetail</th>\n",
       "      <th>reachable</th>\n",
       "      <th>origin_type</th>\n",
       "      <th>origin_prognosisType</th>\n",
       "      <th>origin_plannedTimeZoneOffset</th>\n",
       "      <th>origin_plannedDateTime</th>\n",
       "      <th>origin_plannedTrack</th>\n",
       "      <th>origin_checkinStatus</th>\n",
       "      <th>origin_notes</th>\n",
       "      <th>origin_name</th>\n",
       "      <th>origin_lng</th>\n",
       "      <th>origin_lat</th>\n",
       "      <th>origin_countryCode</th>\n",
       "      <th>origin_uicCode</th>\n",
       "      <th>origin_weight</th>\n",
       "      <th>origin_products</th>\n",
       "      <th>destination_type</th>\n",
       "      <th>destination_prognosisType</th>\n",
       "      <th>destination_plannedTimeZoneOffset</th>\n",
       "      <th>destination_plannedDateTime</th>\n",
       "      <th>destination_plannedTrack</th>\n",
       "      <th>destination_exitSide</th>\n",
       "      <th>destination_checkinStatus</th>\n",
       "      <th>destination_notes</th>\n",
       "      <th>destination_name</th>\n",
       "      <th>destination_lng</th>\n",
       "      <th>destination_lat</th>\n",
       "      <th>destination_countryCode</th>\n",
       "      <th>destination_uicCode</th>\n",
       "      <th>destination_weight</th>\n",
       "      <th>destination_products</th>\n",
       "      <th>product_number</th>\n",
       "      <th>product_categoryCode</th>\n",
       "      <th>product_shortCategoryName</th>\n",
       "      <th>product_longCategoryName</th>\n",
       "      <th>product_operatorCode</th>\n",
       "      <th>product_operatorName</th>\n",
       "      <th>product_type</th>\n",
       "      <th>product_displayName</th>\n",
       "      <th>origin_actualTimeZoneOffset</th>\n",
       "      <th>origin_actualDateTime</th>\n",
       "      <th>destination_actualTimeZoneOffset</th>\n",
       "      <th>destination_actualDateTime</th>\n",
       "      <th>meta_ctxRecon</th>\n",
       "      <th>meta_status</th>\n",
       "      <th>meta_transfers</th>\n",
       "      <th>meta_plannedDurationInMinutes</th>\n",
       "      <th>meta_actualDurationInMinutes</th>\n",
       "      <th>meta_punctuality</th>\n",
       "      <th>meta_realtime</th>\n",
       "      <th>meta_optimal</th>\n",
       "      <th>meta_shareUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SPR 5710</td>\n",
       "      <td>PUBLIC_TRANSIT</td>\n",
       "      <td>Hoofddorp</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1|310166|0|884|18012020</td>\n",
       "      <td>[{'value': '+eas, source RAST attributonstatio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'notes': [{'value': 'Station Accessible or T...</td>\n",
       "      <td>[]</td>\n",
       "      <td>LOW</td>\n",
       "      <td>100.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'type': 'TRAIN_XML', 'link': {'uri': 'https:...</td>\n",
       "      <td>False</td>\n",
       "      <td>STATION</td>\n",
       "      <td>PROGNOSED</td>\n",
       "      <td>60</td>\n",
       "      <td>2020-01-18 06:11:00+01:00</td>\n",
       "      <td>3</td>\n",
       "      <td>CHECKIN</td>\n",
       "      <td>[{'value': 'Station Accessible or Travel Assis...</td>\n",
       "      <td>Amsterdam Zuid</td>\n",
       "      <td>4.873061</td>\n",
       "      <td>52.339027</td>\n",
       "      <td>NL</td>\n",
       "      <td>8400061</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>STATION</td>\n",
       "      <td>PROGNOSED</td>\n",
       "      <td>60</td>\n",
       "      <td>2020-01-18 06:17:00+01:00</td>\n",
       "      <td>3</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>NOTHING</td>\n",
       "      <td>[{'value': 'Station Accessible or Travel Assis...</td>\n",
       "      <td>Schiphol Airport</td>\n",
       "      <td>4.762269</td>\n",
       "      <td>52.308293</td>\n",
       "      <td>NL</td>\n",
       "      <td>8400561</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5710</td>\n",
       "      <td>SPR</td>\n",
       "      <td>SPR</td>\n",
       "      <td>Sprinter</td>\n",
       "      <td>ns</td>\n",
       "      <td>NS</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>NS Sprinter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>arnu|fromStation=8400061|toStation=8400319|pla...</td>\n",
       "      <td>CANCELLED</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>90.9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{'uri': 'https://www.ns.nl/rpx?ctx=arnu%7Cfrom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  idx      name      travelType  direction  cancelled  changePossible  \\\n",
       "0   0  SPR 5710  PUBLIC_TRANSIT  Hoofddorp      False            True   \n",
       "\n",
       "   alternativeTransport         journeyDetailRef  \\\n",
       "0                 False  1|310166|0|884|18012020   \n",
       "\n",
       "                                               notes messages  \\\n",
       "0  [{'value': '+eas, source RAST attributonstatio...       []   \n",
       "\n",
       "                                               stops steps crowdForecast  \\\n",
       "0  [{'notes': [{'value': 'Station Accessible or T...    []           LOW   \n",
       "\n",
       "   punctuality crossPlatformTransfer  shorterStock  \\\n",
       "0        100.0                 False         False   \n",
       "\n",
       "                                       journeyDetail  reachable origin_type  \\\n",
       "0  [{'type': 'TRAIN_XML', 'link': {'uri': 'https:...      False     STATION   \n",
       "\n",
       "  origin_prognosisType  origin_plannedTimeZoneOffset  \\\n",
       "0            PROGNOSED                            60   \n",
       "\n",
       "     origin_plannedDateTime origin_plannedTrack origin_checkinStatus  \\\n",
       "0 2020-01-18 06:11:00+01:00                   3              CHECKIN   \n",
       "\n",
       "                                        origin_notes     origin_name  \\\n",
       "0  [{'value': 'Station Accessible or Travel Assis...  Amsterdam Zuid   \n",
       "\n",
       "   origin_lng  origin_lat origin_countryCode origin_uicCode  origin_weight  \\\n",
       "0    4.873061   52.339027                 NL        8400061             -1   \n",
       "\n",
       "   origin_products destination_type destination_prognosisType  \\\n",
       "0               -1          STATION                 PROGNOSED   \n",
       "\n",
       "   destination_plannedTimeZoneOffset destination_plannedDateTime  \\\n",
       "0                                 60   2020-01-18 06:17:00+01:00   \n",
       "\n",
       "  destination_plannedTrack destination_exitSide destination_checkinStatus  \\\n",
       "0                        3                RIGHT                   NOTHING   \n",
       "\n",
       "                                   destination_notes  destination_name  \\\n",
       "0  [{'value': 'Station Accessible or Travel Assis...  Schiphol Airport   \n",
       "\n",
       "   destination_lng  destination_lat destination_countryCode  \\\n",
       "0         4.762269        52.308293                      NL   \n",
       "\n",
       "  destination_uicCode  destination_weight  destination_products  \\\n",
       "0             8400561                  -1                    -1   \n",
       "\n",
       "  product_number product_categoryCode product_shortCategoryName  \\\n",
       "0           5710                  SPR                       SPR   \n",
       "\n",
       "  product_longCategoryName product_operatorCode product_operatorName  \\\n",
       "0                 Sprinter                   ns                   NS   \n",
       "\n",
       "  product_type product_displayName  origin_actualTimeZoneOffset  \\\n",
       "0        TRAIN         NS Sprinter                          NaN   \n",
       "\n",
       "  origin_actualDateTime  destination_actualTimeZoneOffset  \\\n",
       "0                   NaT                               NaN   \n",
       "\n",
       "  destination_actualDateTime  \\\n",
       "0                        NaT   \n",
       "\n",
       "                                       meta_ctxRecon meta_status  \\\n",
       "0  arnu|fromStation=8400061|toStation=8400319|pla...   CANCELLED   \n",
       "\n",
       "  meta_transfers meta_plannedDurationInMinutes meta_actualDurationInMinutes  \\\n",
       "0              2                            97                           97   \n",
       "\n",
       "  meta_punctuality meta_realtime meta_optimal  \\\n",
       "0             90.9          True        False   \n",
       "\n",
       "                                       meta_shareUrl  \n",
       "0  {'uri': 'https://www.ns.nl/rpx?ctx=arnu%7Cfrom...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date_time_column(target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diff = target_train['origin_actualDateTime'] - target_train['origin_plannedDateTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff.values.item()/60000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def status(target_train):\n",
    "#     status='normal'\n",
    "#     delayed_min = 0 \n",
    "#     url_to_html = target_train['meta_shareUrl'].values.item()['uri']\n",
    "#     if target_train['cancelled'].bool() == True:\n",
    "#         status = 'cancelled'\n",
    "#     else:\n",
    "#         try:\n",
    "#             diff = target_train['origin_actualDateTime'] - target_train['origin_plannedDateTime']\n",
    "#             delayed_min = diff.values.item()/60000000000\n",
    "#             if delayed_min > 5 :\n",
    "#                 status = 'delayed > 5 mins'\n",
    "#             else:\n",
    "#                 status = 'delayed <= 5 mins'\n",
    "#         except:\n",
    "#             if target_train['meta_status'].values.item() != 'NORMAL':\n",
    "#                 status = target_train['meta_status'].values.item()\n",
    "#             else: \n",
    "#                 status = 'normal'\n",
    "#         pass\n",
    "    \n",
    "#     return status, int(delayed_min), url_to_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status, delayed_min, url_to_html = status(target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CANCELLED'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delayed_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.ns.nl/rpx?ctx=arnu%7CfromStation%3D8400061%7CtoStation%3D8400319%7CplannedFromTime%3D2020-01-18T06%3A11%3A00%2B01%3A00%7CplannedArrivalTime%3D2020-01-18T07%3A48%3A00%2B01%3A00%7CyearCard%3Dfalse%7CexcludeHighSpeedTrains%3Dfalse'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url_to_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import smtplib\n",
    "\n",
    "# gmail_user = os.getenv('GMAIL_USER')\n",
    "# gmail_password = os.getenv('GMAIL_PWD')\n",
    "# server = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
    "# server.ehlo()\n",
    "# server.login(gmail_user, gmail_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#txt_html = requests.get(url_to_html).text\n",
    "#urllib.request.urlopen(url_to_html).read().decode(\"utf-8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<div class=\"rp-reisadvies\"></reisadvies>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import smtplib, ssl\n",
    "# from email.mime.text import MIMEText\n",
    "# from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "# def send_email(status, delayed_min, url_to_html ):\n",
    "\n",
    "#     sender_email = os.getenv('GMAIL_USER')\n",
    "#     receiver_email = [i.strip() for i in list(os.getenv(\"SEND_TO\").split(\";\"))][1]\n",
    "#     password = os.getenv('GMAIL_PWD')\n",
    "\n",
    "#     message = MIMEMultipart(\"alternative\")\n",
    "#     message[\"Subject\"] = 'Train '+status+'!'\n",
    "#     message[\"From\"] = sender_email\n",
    "#     message[\"To\"] = receiver_email\n",
    "\n",
    "#     # Create the plain-text and HTML version of your message\n",
    "#     text = \"\"\"\\\n",
    "#     Hi,\n",
    "#     \"\"\" + url_to_html\n",
    "#     html = '' #requests.get(url_to_html).text \n",
    "\n",
    "#     # Turn these into plain/html MIMEText objects\n",
    "#     part1 = MIMEText(text, \"plain\")\n",
    "#     part2 = MIMEText(html, \"html\")\n",
    "\n",
    "#     # Add HTML/plain-text parts to MIMEMultipart message\n",
    "#     # The email client will try to render the last part first\n",
    "#     message.attach(part1)\n",
    "#     message.attach(part2)\n",
    "\n",
    "#     # Create secure connection with server and send email\n",
    "#     context = ssl.create_default_context()\n",
    "#     with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465, context=context) as server:\n",
    "#         server.login(sender_email, password)\n",
    "#         server.sendmail(\n",
    "#             sender_email, receiver_email, message.as_string()\n",
    "#         )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def notification():\n",
    "#     message = ''\n",
    "#     if \n",
    "#     elif 'origin.actualDateTime' in intersection:\n",
    "#         m = 'Delayed by' + \n",
    "#         #print('Delayed')\n",
    "    \n",
    "#     else:\n",
    "#         m = 'OK'\n",
    "#         #print('OK')\n",
    "#     return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notification()\n",
    "# m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def df_to_s3(df, table_name, schema, dtype=None, sep='\\t', delete_first=False, clean_df=False, keep_csv=True, chunksize=10000, if_exists=\"fail\", redshift_str=None, bucket=None):\n",
    "\n",
    "#     \"\"\"Copies a dataframe inside a Redshift schema.table\n",
    "#         using the bulk upload via this process:\n",
    "#         df -> local csv -> s3 csv -> redshift table\n",
    "\n",
    "#         NOTE: currently this function performs a delete * in\n",
    "#         the target table, append is in TODO list, also we\n",
    "#         need to add a timestamp column\n",
    "\n",
    "#         COLUMN TYPES: right now you need to do a DROP TABLE to\n",
    "#         change the column type, this needs to be changed TODO\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     keep_csv : bool, optional\n",
    "#         Whether to keep the local csv copy after uploading it to Amazon S3, by default True\n",
    "#     redshift_str : str, optional\n",
    "#         Redshift engine string, if None then 'mssql+pyodbc://Redshift'\n",
    "#     bucket : str, optional\n",
    "#         Bucket name, if None then 'teis-data'\n",
    "#     \"\"\"\n",
    "\n",
    "#     ACCESS_KEY = os.getenv('AWS_ACCESS')\n",
    "#     SECRET_KEY = os.getenv('AWS_SECRET')\n",
    "#     REGION = os.getenv('AWS_REGION')\n",
    "\n",
    "#     redshift_str = redshift_str if redshift_str else 'mssql+pyodbc://Redshift'\n",
    "#     bucket_name = bucket if bucket else 'bing'\n",
    "\n",
    "#     engine = create_engine(redshift_str, encoding='utf8', poolclass=NullPool)\n",
    "\n",
    "#     s3 = boto3.resource('s3', aws_access_key_id=ACCESS_KEY, aws_secret_access_key=SECRET_KEY, region_name=REGION)\n",
    "#     bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "#     filename = table_name + '.csv'\n",
    "#     filepath = os.path.join(os.getcwd(), filename)\n",
    "\n",
    "#     if delete_first:\n",
    "#         remove_from_s3(table_name)\n",
    "#         s3_file = s3.Object(bucket_name, filename)\n",
    "#         s3_file.delete()\n",
    "\n",
    "#     if clean_df:\n",
    "#         df = df_clean(df)\n",
    "\n",
    "#     df = clean_colnames(df)\n",
    "#     df.columns = df.columns.str.strip().str.replace(\" \", \"_\") # Redshift won't accept column names with spaces\n",
    "\n",
    "#     df.to_csv(filepath, sep=\"\\t\", encoding=\"utf-8\", index=False, chunksize=chunksize)\n",
    "#     print(f'{filename} created in {filepath}')\n",
    "\n",
    "#     bucket.upload_file(filepath, f\"bulk/{filename}\")\n",
    "#     print(f'bulk/{filename} file uploaded to s3')\n",
    "\n",
    "#     if check_if_exists(table_name, schema, redshift_str=redshift_str):\n",
    "#         if if_exists == 'fail':\n",
    "#             raise ValueError(f\"Table {table_name} already exists\")\n",
    "#         elif if_exists == 'replace':\n",
    "#             sql = f\"DELETE FROM {schema}.{table_name}\"\n",
    "#             engine.execute(sql)\n",
    "#             print('SQL table has been cleaned up successfully.')\n",
    "#         else:\n",
    "#             pass\n",
    "#     else:\n",
    "#         df.head(1).to_sql(table_name, schema=schema, index=False, con=engine, dtype=dtype)\n",
    "\n",
    "#     if not keep_csv:\n",
    "#         os.remove(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dateTime (optional)string\n",
    "#Format - date-time (as date-time in RFC3339). Departure date / time for the search. defaults to server time (Europe/Amsterdam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #disruptions\n",
    "# headers = {\n",
    "#     # Request headers\n",
    "#     'Ocp-Apim-Subscription-Key': '%s' % key ,\n",
    "# }\n",
    "\n",
    "# params = urllib.parse.urlencode({\n",
    "#     # Request parameters\n",
    "#     'type': '{string}',\n",
    "#     'actual': '{boolean}',\n",
    "#     'lang': 'en',\n",
    "# })\n",
    "\n",
    "# try:\n",
    "#     conn = http.client.HTTPSConnection('gateway.apiportal.ns.nl')\n",
    "#     conn.request(\"GET\", \"/public-reisinformatie/api/v2/disruptions?%s\" % params, \"{body}\", headers)\n",
    "#     response = conn.getresponse()\n",
    "#     disruption = response.read()\n",
    "#     #print(data)\n",
    "#     conn.close()\n",
    "# except Exception as e:\n",
    "#     print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# station = \"amsterdamzuid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Disruption station\n",
    "# headers = {\n",
    "#     # Request headers\n",
    "#     'Ocp-Apim-Subscription-Key': '%s' % key ,\n",
    "# }\n",
    "\n",
    "# params = urllib.parse.urlencode({\n",
    "# })\n",
    "\n",
    "# try:\n",
    "#     conn = http.client.HTTPSConnection('gateway.apiportal.ns.nl')\n",
    "#     conn.request(\"GET\", \"/public-reisinformatie/api/v2/disruptions/station/%s\" % station, \"{body}\", headers)\n",
    "#     response = conn.getresponse()\n",
    "#     disrupt_station = response.read()\n",
    "#     #print(data)\n",
    "#     conn.close()\n",
    "# except Exception as e:\n",
    "#     print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This doesn't work yet\n",
    "# uid_add = \"http://webservices.ns.nl/ns-api-stations-v2?_ga=2.141585782.518451146.1577077875-2005063189.1572857950\"\n",
    "# key = os.getenv(\"NS_KEY\")\n",
    "\n",
    "# headers = {\n",
    "#     # Request headers\n",
    "#     'Ocp-Apim-Subscription-Key': '%s' % key,\n",
    "# } \n",
    "# try:\n",
    "#     conn = http.client.HTTPSConnection('gateway.apiportal.ns.nl')\n",
    "#     conn.request(\"GET\", uid_add, \"{body}\", headers)\n",
    "#     response = conn.getresponse()\n",
    "#     uid = response.read()\n",
    "#     #print(data)\n",
    "#     conn.close()\n",
    "# except Exception as e:\n",
    "#     print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code used to explore json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeatNamespace(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trips = d['trips'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeatNamespace(trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "legs = d['trips'][0]['legs'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(legs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeatNamespace(legs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(legs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore dictionary in old way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_lcopy = df['legs'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_lcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "frames = []\n",
    "for i in range(len(df_lcopy)):    \n",
    "    frames.append(json_normalize(df_lcopy[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_leg = pd.concat(frames, sort='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_leg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df_unpack[df_unpack['name']==train_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df_unpack.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df_trips.query('transfers == 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df_leg['destination.notes'].values\n",
    "#df_leg['notes'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns_select = ['destination.prognosisType', 'origin.name','destination.name', 'cancelled','origin.plannedDateTime', 'origin.actualDateTime', 'destination.plannedDateTime','punctuality']\n",
    "all_columns = df_leg.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "intersection = set(columns_select) & set(all_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_an = df_leg[intersection]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date_time_col = intersection.islike('%Date%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_an"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_an = pd.to_datetime(df_an['origin.plannedDateTime'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import smtplib\n",
    "\n",
    "# def send_email(status, delayed_min, url_to_html ):\n",
    "#     gmail_user = os.getenv('GMAIL_USER')\n",
    "#     gmail_password = os.getenv('GMAIL_PWD')\n",
    "#     send_to = [i.strip() for i in list(os.getenv(\"SEND_TO\").split(\";\"))]\n",
    "\n",
    "#     sent_from = gmail_user\n",
    "#     to = send_to\n",
    "#     subject = 'Train '+status+'!'\n",
    "#     body = 'test'\n",
    "\n",
    "#     email_text = \"\"\"\\\n",
    "#     From: %s\n",
    "#     To: %s\n",
    "#     Subject: %s\n",
    "#     Body:\n",
    "#     %s\n",
    "#     \"\"\" % (sent_from,'b.luo.pmp@gmail.com' , subject, body) # \"; \".join(to)\n",
    "#     server = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
    "#     server.ehlo()\n",
    "#     server.login(gmail_user, gmail_password)\n",
    "#     server.sendmail(sent_from, to, email_text)\n",
    "#     server.close()\n",
    "    \n",
    "# #     try:\n",
    "# #         server = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
    "# #         server.ehlo()\n",
    "# #         server.login(gmail_user, gmail_password)\n",
    "# #         server.sendmail(sent_from, to, email_text)\n",
    "# #         server.close()\n",
    "\n",
    "# #         print('Email sent!')\n",
    "# #     except:\n",
    "# #         print('Something went wrong...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
